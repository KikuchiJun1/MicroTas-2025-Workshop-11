{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywldiczVoqEy"
      },
      "source": [
        "# Segmentation Tutorial: Classical Methods + UNet\n",
        "\n",
        "This tutorial combines basic classical image segmentation techniques with a minimal UNet training/inference workflow on the NuInsSeg dataset contained in this repository. It is designed to run training for only 1 epoch on a small subset.\n",
        "\n",
        "What you'll do:\n",
        "- Explore classical segmentation: grayscale, Otsu thresholding, simple morphology, Sobel edges.\n",
        "- Train a small UNet for 1 epoch on a limited subset.\n",
        "- Load a pretrained checkpoint (if available under `runs/`) and run inference.\n",
        "\n",
        "Notes:\n",
        "- Data: this uses the `NuInsSeg/` tree (e.g., `human spleen/tissue images` + `\n",
        "mask binary`).\n",
        "- Keep the subset size small (`LIMIT`) and the image size moderate (`IMG_SIZE`).\n",
        "- GPU is recommended but not required.\n"
      ],
      "id": "ywldiczVoqEy"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f1d43aef",
      "metadata": {
        "id": "f1d43aef",
        "outputId": "6a99cfb1-f4dc-4f5d-9ce6-e8014b335111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repository...\n",
            "Repository cloned successfully!\n",
            "Working directory: /content/segmentation_repo\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Setup 1: Ensure correct working directory\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Check if we need to clone (Colab case)\n",
        "if not os.path.exists('train_unet'):\n",
        "    print(\"Cloning repository...\")\n",
        "    subprocess.run(['git', 'clone', 'https://github.com/KikuchiJun1/MicroTas-2025-Workshop-11.git', 'segmentation_repo'], check=True)\n",
        "    os.chdir('segmentation_repo')\n",
        "    print(\"Repository cloned successfully!\")\n",
        "else:\n",
        "    # Already in the repo directory (local case)\n",
        "    print(\"✓ Repository directory detected\")\n",
        "\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2b4f78e8",
      "metadata": {
        "id": "2b4f78e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583ecc65-6fa9-4175-ead2-3eda0b7b029f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Setup 2: Import Required Libraries\n",
        "\n",
        "import random, time\n",
        "from PIL import Image, ImageFilter, ImageOps\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from segmentation.train_unet.dataset_nuinsseg import discover_pairs, NuInsSegDataset\n",
        "from segmentation.train_unet.transforms import build_transforms\n",
        "from segmentation.train_unet.model_unet import UNet\n",
        "from segmentation.train_unet.utils import set_seed, bce_dice_loss, dice_coeff, iou_score, AverageMeter, ensure_dir, count_parameters\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "da40db4f",
      "metadata": {
        "id": "da40db4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01d8bc2f-3710-48c7-9bb8-fe0117ada61c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Setup 3: Configuration & Download Pretrained Weights\n",
        "\n",
        "set_seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}')\n",
        "\n",
        "# Configuration\n",
        "DATA_ROOT = 'segmentation/NuInsSeg'\n",
        "INCLUDE = ['human_spleen']\n",
        "IMG_SIZE = 256\n",
        "LIMIT = 40      # total pairs used (keep small for speed)\n",
        "VAL_FRAC = 0.2\n",
        "TEST_FRAC = 0.1\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 10\n",
        "OUTDIR = 'segmentation/runs/tutorial_classical_unet'\n",
        "ensure_dir(OUTDIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76dd0555",
      "metadata": {
        "id": "76dd0555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65e2f3b-856c-4caf-82bd-609cb5203387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to download pretrained weights from Google Drive...\n"
          ]
        }
      ],
      "source": [
        "# Setup 4: Download Pretrained Weights (Optional)\n",
        "\n",
        "WEIGHTS_URL = 'https://drive.google.com/uc?id=1tjfTRYWWf1OlsHml1-DltZuIA6O71_ro'\n",
        "WEIGHTS_PATH = os.path.join('segmentation','runs', 'expD2', 'best.pt')\n",
        "\n",
        "if not os.path.exists(WEIGHTS_PATH):\n",
        "    os.makedirs(os.path.dirname(WEIGHTS_PATH), exist_ok=True)\n",
        "    print(\"Attempting to download pretrained weights from Google Drive...\")\n",
        "    try:\n",
        "        # Install gdown\n",
        "        subprocess.run(['pip', 'install', '-q', 'gdown'], check=True)\n",
        "        # Download weights\n",
        "        subprocess.run(['gdown', WEIGHTS_URL, '-O', WEIGHTS_PATH], check=True)\n",
        "        print(f\"✓ Weights downloaded successfully to {WEIGHTS_PATH}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"⚠️ Could not download weights: {e}\")\n",
        "        print(f\"   Weights will be optional - training model will be used for inference\")\n",
        "else:\n",
        "    print(f\"✓ Weights already exist at {WEIGHTS_PATH}\")\n",
        "\n",
        "print(\"\\nSetup complete! Ready to start segmentation tutorial.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WibCacruoqE0"
      },
      "outputs": [],
      "source": [
        "# Helper functions: visualization, Otsu threshold, Sobel edges, simple morphology\n",
        "\n",
        "def to_gray_uint8(pil_img):\n",
        "    return np.asarray(pil_img.convert('L'), dtype=np.uint8)\n",
        "\n",
        "def overlay_mask(rgb_img, mask, color=(255, 0, 0), alpha=0.4):\n",
        "    if isinstance(rgb_img, Image.Image):\n",
        "        base = np.asarray(rgb_img.convert('RGB')).copy()\n",
        "    else:\n",
        "        base = np.asarray(rgb_img).copy()\n",
        "    m = (mask > 0)\n",
        "    overlay = np.zeros_like(base)\n",
        "    overlay[m] = np.array(color, dtype=np.uint8)\n",
        "    out = (base * (1 - alpha) + overlay * alpha).clip(0, 255).astype(np.uint8)\n",
        "    return out\n",
        "\n",
        "def show_triplet(img, pred_mask, gt_mask, title=''):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1,3,1); plt.imshow(img); plt.axis('off'); plt.title('Image')\n",
        "    plt.subplot(1,3,2); plt.imshow(pred_mask, cmap='gray'); plt.axis('off'); plt.title('Prediction')\n",
        "    plt.subplot(1,3,3); plt.imshow(gt_mask, cmap='gray'); plt.axis('off'); plt.title('Ground Truth')\n",
        "    if title: plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "def otsu_threshold(gray_uint8):\n",
        "    # gray_uint8: HxW in [0..255]\n",
        "    hist = np.bincount(gray_uint8.ravel(), minlength=256).astype(np.float64)\n",
        "    p = hist / (hist.sum() + 1e-12)\n",
        "    omega = np.cumsum(p)\n",
        "    mu = np.cumsum(p * np.arange(256))\n",
        "    mu_t = mu[-1]\n",
        "    denom = (omega * (1.0 - omega))\n",
        "    denom[denom == 0] = np.nan\n",
        "    sigma_b2 = (mu_t * omega - mu)**2 / denom\n",
        "    t = int(np.nanargmax(sigma_b2))\n",
        "    return t\n",
        "\n",
        "def _to_tensor01(x):\n",
        "    return torch.from_numpy(x.astype(np.float32))[None, None]  # [1,1,H,W]\n",
        "\n",
        "def dilate_bin(mask_uint8, k=3, iters=1):\n",
        "    x = _to_tensor01(mask_uint8)\n",
        "    for _ in range(max(1, iters)):\n",
        "        x = torch.nn.functional.max_pool2d(x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return (x.squeeze().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "def erode_bin(mask_uint8, k=3, iters=1):\n",
        "    x = _to_tensor01(mask_uint8)\n",
        "    for _ in range(max(1, iters)):\n",
        "        x = -torch.nn.functional.max_pool2d(-x, kernel_size=k, stride=1, padding=k//2)\n",
        "    return (x.squeeze().numpy() > 0.5).astype(np.uint8)\n",
        "\n",
        "def open_bin(mask_uint8, k=3, iters=1):\n",
        "    return dilate_bin(erode_bin(mask_uint8, k, iters), k, iters)\n",
        "\n",
        "def close_bin(mask_uint8, k=3, iters=1):\n",
        "    return erode_bin(dilate_bin(mask_uint8, k, iters), k, iters)\n",
        "\n",
        "def compute_metrics(pred_mask_uint8, gt_mask_uint8):\n",
        "    p = torch.from_numpy(pred_mask_uint8.astype(np.float32))[None, None]\n",
        "    t = torch.from_numpy(gt_mask_uint8.astype(np.float32))[None, None]\n",
        "    with torch.no_grad():\n",
        "        logits = p  # {0,1} is fine for these metrics\n",
        "        d = dice_coeff(logits, t).item()\n",
        "        i = iou_score(logits, t).item()\n",
        "    return d, i\n",
        "\n",
        "def split_pairs_threeway(pairs, val_frac, test_frac, seed=42):\n",
        "    if val_frac + test_frac >= 1.0:\n",
        "        raise ValueError('val_frac + test_frac must be < 1.0')\n",
        "    n = len(pairs)\n",
        "    rng = random.Random(seed)\n",
        "    idxs = list(range(n)); rng.shuffle(idxs)\n",
        "    n_test = int(n * test_frac)\n",
        "    n_val = int(n * val_frac)\n",
        "    if test_frac > 0 and n_test == 0 and n >= 1: n_test = 1\n",
        "    if val_frac > 0 and n_val == 0 and n - n_test >= 1: n_val = 1\n",
        "    test_idx = set(idxs[:n_test])\n",
        "    val_idx = set(idxs[n_test:n_test+n_val])\n",
        "    train = [pairs[i] for i in idxs if i not in test_idx and i not in val_idx]\n",
        "    val = [pairs[i] for i in val_idx]\n",
        "    test = [pairs[i] for i in test_idx]\n",
        "    return train, val, test\n",
        "\n",
        "def collate_batch(batch):\n",
        "    imgs = torch.stack([b.image for b in batch], dim=0)\n",
        "    msks = torch.stack([b.mask for b in batch], dim=0)\n",
        "    paths = [(b.img_path, b.msk_path) for b in batch]\n",
        "    return imgs, msks, paths\n"
      ],
      "id": "WibCacruoqE0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqCnNsp2oqE0"
      },
      "outputs": [],
      "source": [
        "# Discover pairs and preview\n",
        "\n",
        "pairs = discover_pairs(DATA_ROOT, include=INCLUDE)\n",
        "if LIMIT and LIMIT > 0 and len(pairs) > LIMIT:\n",
        "    pairs = pairs[:LIMIT]\n",
        "print(f'Found {len(pairs)} image/mask pairs (limited).')\n",
        "\n",
        "train_pairs, val_pairs, test_pairs = split_pairs_threeway(pairs, VAL_FRAC, TEST_FRAC, seed=42)\n",
        "print(f'Train: {len(train_pairs)} | Val: {len(val_pairs)} | Test: {len(test_pairs)}')\n",
        "\n",
        "# Preview a few samples\n",
        "num_preview = min(3, len(pairs))\n",
        "plt.figure(figsize=(12, 4*num_preview))\n",
        "for i in range(num_preview):\n",
        "    img_p, msk_p = pairs[i]\n",
        "    img = Image.open(img_p).convert('RGB')\n",
        "    msk = (np.asarray(Image.open(msk_p).convert('L')) > 0).astype(np.uint8)\n",
        "    over = overlay_mask(img, msk*255, color=(0,255,0), alpha=0.35)\n",
        "    plt.subplot(num_preview, 2, 2*i+1); plt.imshow(img); plt.axis('off'); plt.title(os.path.basename(img_p))\n",
        "    plt.subplot(num_preview, 2, 2*i+2); plt.imshow(over); plt.axis('off'); plt.title('Overlay GT mask')\n",
        "plt.show()\n"
      ],
      "id": "fqCnNsp2oqE0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxPvGKkmoqE0"
      },
      "outputs": [],
      "source": [
        "# Classical method: Otsu threshold + morphology\n",
        "\n",
        "val_eval = []\n",
        "n_demo = min(4, len(val_pairs))\n",
        "for i in range(n_demo):\n",
        "    img_p, msk_p = val_pairs[i]\n",
        "    img = Image.open(img_p).convert('RGB')\n",
        "    gt = (np.asarray(Image.open(msk_p).convert('L')) > 0).astype(np.uint8)\n",
        "    # slight blur to denoise before thresholding\n",
        "    img_blur = img.filter(ImageFilter.GaussianBlur(radius=1))\n",
        "    gray = to_gray_uint8(img_blur)\n",
        "    t = otsu_threshold(gray)\n",
        "    pred = (gray < t).astype(np.uint8)\n",
        "    # small opening to remove speckles\n",
        "    pred = open_bin(pred, k=3, iters=1)\n",
        "    d, iou = compute_metrics(pred, gt)\n",
        "    val_eval.append((d, iou))\n",
        "    show_triplet(img, pred*255, gt*255, title=f'Otsu+Open | Dice={d:.3f}, IoU={iou:.3f}')\n",
        "\n",
        "if val_eval:\n",
        "    md = float(np.mean([x[0] for x in val_eval]))\n",
        "    mi = float(np.mean([x[1] for x in val_eval]))\n",
        "    print(f'Classical (Otsu+Open) on {len(val_eval)} samples -> Dice={md:.3f}, IoU={mi:.3f}')\n",
        "else:\n",
        "    print('No validation pairs to demo classical method.')\n"
      ],
      "id": "PxPvGKkmoqE0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a26877ae",
      "metadata": {
        "id": "a26877ae"
      },
      "outputs": [],
      "source": [
        "# Prepare Datasets and DataLoaders\n",
        "\n",
        "# Build transforms for training and validation\n",
        "# Training: includes augmentation (rotation, flipping, etc.) for better generalization\n",
        "# Validation: no augmentation, just normalization\n",
        "train_t, val_t = build_transforms(IMG_SIZE, augment=True)\n",
        "print(f\"✓ Transforms created for IMG_SIZE={IMG_SIZE}\")\n",
        "\n",
        "# Create datasets\n",
        "# NuInsSegDataset loads image/mask pairs and applies transforms\n",
        "train_ds = NuInsSegDataset(train_pairs, transform=train_t, img_size=IMG_SIZE)\n",
        "val_ds = NuInsSegDataset(val_pairs, transform=val_t, img_size=IMG_SIZE)\n",
        "print(f\"✓ Training dataset: {len(train_ds)} samples\")\n",
        "print(f\"✓ Validation dataset: {len(val_ds)} samples\")\n",
        "\n",
        "# Create DataLoaders for batching and parallel loading\n",
        "# num_workers=2: parallel loading (faster on GPU)\n",
        "# pin_memory=True: faster GPU data transfer\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,           # shuffle training data for better learning\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_batch\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=max(1, BATCH_SIZE//2),  # smaller batch for validation\n",
        "    shuffle=False,          # don't shuffle validation data\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_batch\n",
        ")\n",
        "print(f\"✓ Train batches: {len(train_loader)} | Val batches: {len(val_loader)}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d32d0a05",
      "metadata": {
        "id": "d32d0a05"
      },
      "outputs": [],
      "source": [
        "# Initialize UNet Model\n",
        "\n",
        "# Create small UNet with base channels=16 (lightweight for fast training)\n",
        "# Larger base_ch values (e.g., 64) = more parameters but slower training\n",
        "model_small = UNet(n_channels=3, n_classes=1, base_ch=16).to(device)\n",
        "total_params = count_parameters(model_small)\n",
        "print(f\"✓ UNet Model created\")\n",
        "print(f\"  - Input channels: 3 (RGB)\")\n",
        "print(f\"  - Output channels: 1 (binary segmentation)\")\n",
        "print(f\"  - Base channels: 16\")\n",
        "print(f\"  - Total parameters: {total_params:,}\")\n",
        "\n",
        "# Initialize optimizer\n",
        "# Adam: adaptive learning rate optimizer (good for most tasks)\n",
        "# lr=1e-3: learning rate (0.001)\n",
        "opt = torch.optim.Adam(model_small.parameters(), lr=1e-3)\n",
        "print(f\"✓ Optimizer: Adam (lr=1e-3)\")\n",
        "\n",
        "# Track best validation performance\n",
        "best_dice = -1.0\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83a7109c",
      "metadata": {
        "id": "83a7109c"
      },
      "outputs": [],
      "source": [
        "# Train UNet Model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Suppress warnings for cleaner output\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # ===== TRAINING PHASE =====\n",
        "    model_small.train()  # enable training mode (dropout, batch norm active)\n",
        "    train_loss = AverageMeter()  # track average loss per epoch\n",
        "\n",
        "    for step, (imgs, msks, _) in enumerate(train_loader, 1):\n",
        "        # Move data to GPU/CPU\n",
        "        imgs = imgs.to(device, non_blocking=True)\n",
        "        msks = msks.to(device, non_blocking=True)\n",
        "\n",
        "        # Forward pass\n",
        "        opt.zero_grad(set_to_none=True)  # clear previous gradients\n",
        "        logits = model_small(imgs)  # predict segmentation masks\n",
        "\n",
        "        # Compute loss (binary cross-entropy + Dice loss)\n",
        "        loss = bce_dice_loss(logits, msks)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()  # compute gradients\n",
        "        opt.step()  # update weights\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss.update(loss.item(), imgs.size(0))\n",
        "\n",
        "        # Print progress every 10 steps\n",
        "        if step % 10 == 0:\n",
        "            print(f'  Epoch {epoch+1}/{EPOCHS} | Step {step}/{len(train_loader)} | Loss {train_loss.avg:.4f}')\n",
        "\n",
        "    # ===== VALIDATION PHASE =====\n",
        "    model_small.eval()  # disable training mode (dropout off, batch norm frozen)\n",
        "    val_loss = AverageMeter()\n",
        "    val_dice = AverageMeter()\n",
        "    val_iou = AverageMeter()\n",
        "\n",
        "    with torch.no_grad():  # disable gradient computation for speed\n",
        "        for imgs, msks, _ in val_loader:\n",
        "            imgs = imgs.to(device, non_blocking=True)\n",
        "            msks = msks.to(device, non_blocking=True)\n",
        "\n",
        "            logits = model_small(imgs)\n",
        "            loss = bce_dice_loss(logits, msks)\n",
        "\n",
        "            # Update validation metrics\n",
        "            val_loss.update(loss.item(), imgs.size(0))\n",
        "            val_dice.update(dice_coeff(logits, msks).item(), imgs.size(0))\n",
        "            val_iou.update(iou_score(logits, msks).item(), imgs.size(0))\n",
        "\n",
        "    # Print epoch summary\n",
        "    print(f'Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss.avg:.4f} | Val Loss: {val_loss.avg:.4f}')\n",
        "    print(f'           | Dice: {val_dice.avg:.4f} | IoU: {val_iou.avg:.4f}')\n",
        "\n",
        "    # Save best model checkpoint\n",
        "    if val_dice.avg > best_dice:\n",
        "        best_dice = val_dice.avg\n",
        "        ckpt_path = os.path.join(OUTDIR, 'best.pt')\n",
        "        torch.save({'epoch': epoch+1, 'model': model_small.state_dict()}, ckpt_path)\n",
        "        print(f'  ✓ Saved best checkpoint to {ckpt_path}')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"Training complete! Best Dice Score: {best_dice:.4f}\")\n",
        "print(\"=\" * 60)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae1049de",
      "metadata": {
        "id": "ae1049de"
      },
      "outputs": [],
      "source": [
        "# Visualize Validation Predictions\n",
        "\n",
        "model_small.eval()\n",
        "n_show = min(2, len(val_ds))\n",
        "print(f\"Showing {n_show} validation predictions:\\n\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_show):\n",
        "        s = val_ds[i]\n",
        "\n",
        "        # Prepare input\n",
        "        img_t = s.image.unsqueeze(0).to(device)\n",
        "\n",
        "        # Predict\n",
        "        logits = model_small(img_t)\n",
        "        prob = torch.sigmoid(logits)[0, 0].cpu().numpy()\n",
        "        pred = (prob >= 0.5).astype(np.uint8)  # threshold at 0.5\n",
        "\n",
        "        # Convert tensors back to numpy for visualization\n",
        "        rgb = (s.image.clamp(0, 1).cpu().permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
        "        gt = s.mask[0].cpu().numpy().astype(np.uint8)\n",
        "\n",
        "        # Visualize\n",
        "        show_triplet(rgb, pred*255, gt*255, title=f'UNet Prediction (Sample {i+1}/{n_show})')\n",
        "\n",
        "print(\"✓ Validation visualization complete!\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0QewqLdoqE1"
      },
      "outputs": [],
      "source": [
        "# Pretrained Inference\n",
        "\n",
        "# Define checkpoint paths to try (in order of preference)\n",
        "ckpt_candidates = [\n",
        "    os.path.join('segmentation','runs', 'expD2', 'best.pt'),  # Pretrained weights\n",
        "    os.path.join(OUTDIR, 'best.pt'),           # Newly trained weights\n",
        "]\n",
        "\n",
        "# Find first available checkpoint\n",
        "ckpt_path = next((p for p in ckpt_candidates if os.path.isfile(p)), None)\n",
        "print(f'Looking for checkpoint...')\n",
        "print(f'Candidate: {ckpt_candidates[0]} → {\"✓ Found\" if os.path.isfile(ckpt_candidates[0]) else \"✗ Not found\"}')\n",
        "print(f'Candidate: {ckpt_candidates[1]} → {\"✓ Found\" if os.path.isfile(ckpt_candidates[1]) else \"✗ Not found\"}')\n",
        "print()\n",
        "\n",
        "if ckpt_path is None:\n",
        "    print('⚠️ No checkpoint found; using the trained model for inference.')\n",
        "    model_pre = model_small\n",
        "else:\n",
        "    print(f'✓ Loading checkpoint from: {ckpt_path}')\n",
        "\n",
        "    # Load checkpoint with weights_only=False (needed for PyTorch 2.6+)\n",
        "    try:\n",
        "        sd = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
        "        sd = sd.get('model', sd)  # extract model weights\n",
        "        print(f'✓ Checkpoint loaded ({len(sd)} parameters)')\n",
        "    except Exception as e:\n",
        "        print(f'⚠️ Failed to load checkpoint: {e}')\n",
        "        model_pre = model_small\n",
        "        ckpt_path = None\n",
        "\n",
        "    # Try to load with different UNet configurations\n",
        "    if ckpt_path is not None:\n",
        "        loaded = False\n",
        "        for base_ch in [64, 32, 16]:\n",
        "            try:\n",
        "                model_pre = UNet(n_channels=3, n_classes=1, base_ch=base_ch).to(device)\n",
        "                model_pre.load_state_dict(sd, strict=True)\n",
        "                print(f'✓ Loaded pretrained UNet with base_ch={base_ch}')\n",
        "                loaded = True\n",
        "                break\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "        if not loaded:\n",
        "            print(f'⚠️ Could not load with any base_ch configuration')\n",
        "            print(f'  Falling back to the trained model')\n",
        "            model_pre = model_small\n",
        "\n",
        "# Run inference on test/validation samples\n",
        "print()\n",
        "print(\"-\" * 60)\n",
        "print(\"Running Inference\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "model_pre.eval()\n",
        "\n",
        "# Use test set if available; otherwise use validation set\n",
        "sample_pairs = test_pairs if len(test_pairs) > 0 else val_pairs\n",
        "n_infer = min(6, len(sample_pairs))\n",
        "print(f'Inferring on {n_infer} {(\"test\" if len(test_pairs) > 0 else \"validation\")} samples:\\n')\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in range(n_infer):\n",
        "        img_p, msk_p = sample_pairs[i]\n",
        "\n",
        "        # Load image and ground truth\n",
        "        img = Image.open(img_p).convert('RGB')\n",
        "        gt = (np.asarray(Image.open(msk_p).convert('L')) > 0).astype(np.uint8)\n",
        "\n",
        "        # Prepare input (normalize to [0, 1])\n",
        "        img_np = np.asarray(img, dtype=np.uint8)\n",
        "        img_t = torch.from_numpy(img_np).float().permute(2, 0, 1) / 255.0\n",
        "        img_t = img_t.unsqueeze(0).to(device)  # add batch dimension\n",
        "\n",
        "        # Predict\n",
        "        logits = model_pre(img_t)\n",
        "        prob = torch.sigmoid(logits)[0, 0].cpu().numpy()\n",
        "        pred = (prob >= 0.5).astype(np.uint8)  # threshold at 0.5\n",
        "\n",
        "        # Visualize\n",
        "        show_triplet(img, pred*255, gt*255,\n",
        "                    title=f'Inference {i+1}/{n_infer}: {os.path.basename(img_p)}')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"✓ Inference complete!\")\n",
        "print(\"=\" * 60)"
      ],
      "id": "b0QewqLdoqE1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive Image Segmentation\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "repo_dir = Path.cwd()\n",
        "content_dir = Path(\"/content\")\n",
        "\n",
        "preset_root = repo_dir / \"segmentation\" / \"NuInsSeg\" / \"other_images\"\n",
        "if not preset_root.is_dir():\n",
        "    alt_root = Path(\"/content/segmentation_repo/segmentation/NuInsSeg/other_images\")\n",
        "    if alt_root.is_dir():\n",
        "        preset_root = alt_root\n",
        "\n",
        "PRESET_NAMES = [\n",
        "    \"human_bladder_03\",\n",
        "    \"human_brain_11\",\n",
        "    \"human_kidney_02\",\n",
        "    \"mouse_muscle_tibia_02\",\n",
        "    \"mouse_thymus_01\",\n",
        "]\n",
        "PRESET_IMAGES = {name: preset_root / f\"{name}.png\" for name in PRESET_NAMES}\n",
        "\n",
        "print(\"Preset image options:\")\n",
        "for name in PRESET_NAMES:\n",
        "    print(f\"  • {name} → {PRESET_IMAGES[name]}\")\n",
        "\n",
        "# ========================== USER SETTINGS ==========================\n",
        "IMAGE_CHOICE = \"mouse_thymus_01\"  # Pick one of PRESET_NAMES or set to None\n",
        "CUSTOM_FILENAME = None             # e.g., \"my_upload.jpg\" if you uploaded a file\n",
        "# ===================================================================\n",
        "\n",
        "uploaded_path = None\n",
        "\n",
        "if IMAGE_CHOICE:\n",
        "    key = IMAGE_CHOICE.strip()\n",
        "    preset_path = PRESET_IMAGES.get(key)\n",
        "    if preset_path and preset_path.is_file():\n",
        "        uploaded_path = preset_path\n",
        "        print(f\"Using preset image: {key}\")\n",
        "        print(f\"   Path: {preset_path}\")\n",
        "    else:\n",
        "        print(f\"Preset image '{key}' not found at {preset_path}\")\n",
        "        print(\"Falling back to CUSTOM_FILENAME workflow…\")\n",
        "        IMAGE_CHOICE = None\n",
        "\n",
        "if uploaded_path is None and CUSTOM_FILENAME:\n",
        "    IMAGE_FILENAME = CUSTOM_FILENAME.strip()\n",
        "    source_path = content_dir / IMAGE_FILENAME\n",
        "    dest_path = repo_dir / IMAGE_FILENAME\n",
        "\n",
        "    if source_path.is_file():\n",
        "        if dest_path.resolve() != source_path.resolve():\n",
        "            shutil.copy2(source_path, dest_path)\n",
        "            print(f\"Copied {IMAGE_FILENAME} from /content to {repo_dir}\")\n",
        "        uploaded_path = dest_path\n",
        "    elif dest_path.is_file():\n",
        "        uploaded_path = dest_path\n",
        "    else:\n",
        "        print()\n",
        "        print(\"Troubleshooting:\")\n",
        "        print(\"  • Upload the image to /content/ in the Colab file browser\")\n",
        "        print(\"  • Keep the filename (with extension) exactly the same\")\n",
        "        print()\n",
        "        if content_dir.exists():\n",
        "            print(\"Files in /content:\")\n",
        "            for f in sorted(content_dir.iterdir()):\n",
        "                if f.suffix.lower() in {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\"}:\n",
        "                    print(f\"  • {f.name}\")\n",
        "        uploaded_path = None\n",
        "\n",
        "print()\n",
        "print(\"=\" * 60)\n",
        "print(\"STEP 1: Find Your Image\")\n",
        "print(\"=\" * 60)\n",
        "print()\n",
        "\n",
        "if uploaded_path:\n",
        "    print(f\"Found your image: {uploaded_path.name}\")\n",
        "else:\n",
        "    print(\"Set IMAGE_CHOICE to one of the preset names above or provide CUSTOM_FILENAME.\")\n",
        "\n",
        "if uploaded_path:\n",
        "    print()\n",
        "    print(\"=\" * 60)\n",
        "    print(\"PROCESSING YOUR IMAGE...\")\n",
        "    print(\"=\" * 60)\n",
        "    print()\n",
        "\n",
        "    try:\n",
        "        img = Image.open(uploaded_path).convert('RGB')\n",
        "        orig_size = img.size\n",
        "        print(f\"Original size: {orig_size[0]} × {orig_size[1]} pixels\")\n",
        "\n",
        "        img_resized = img.resize((IMG_SIZE, IMG_SIZE), Image.BILINEAR)\n",
        "        print(f\"Resized to: {IMG_SIZE} × {IMG_SIZE} pixels (for AI model)\")\n",
        "        print()\n",
        "\n",
        "        img_np = np.asarray(img_resized, dtype=np.uint8)\n",
        "        img_t = torch.from_numpy(img_np).float().permute(2, 0, 1) / 255.0\n",
        "        img_t = img_t.unsqueeze(0).to(device)\n",
        "\n",
        "        print(\"Running AI segmentation...\")\n",
        "        model_pre.eval()\n",
        "        with torch.no_grad():\n",
        "            logits = model_pre(img_t)\n",
        "            prob = torch.sigmoid(logits)[0, 0].cpu().numpy()\n",
        "            pred_mask = (prob >= 0.5).astype(np.uint8)\n",
        "\n",
        "        print(\"Segmentation complete!\")\n",
        "        print()\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "        print(\"RESULTS - 4 Different Views:\")\n",
        "        print(\"-\" * 60)\n",
        "        print()\n",
        "\n",
        "        fig = plt.figure(figsize=(16, 4))\n",
        "\n",
        "        plt.subplot(1, 4, 1)\n",
        "        plt.imshow(img_resized)\n",
        "        plt.axis('off')\n",
        "        plt.title('Your Image\\n(resized)', fontsize=12, fontweight='bold')\n",
        "\n",
        "        plt.subplot(1, 4, 2)\n",
        "        plt.imshow(pred_mask, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.title('Detected Regions\\n(binary mask)', fontsize=12, fontweight='bold')\n",
        "\n",
        "        plt.subplot(1, 4, 3)\n",
        "        im = plt.imshow(prob, cmap='hot')\n",
        "        plt.colorbar(im, fraction=0.046, pad=0.04)\n",
        "        plt.axis('off')\n",
        "        plt.title('AI Confidence\\n(hotter = more confident)', fontsize=12, fontweight='bold')\n",
        "\n",
        "        plt.subplot(1, 4, 4)\n",
        "        overlay = overlay_mask(img_resized, pred_mask * 255, color=(0, 255, 255), alpha=0.5)\n",
        "        plt.imshow(overlay)\n",
        "        plt.axis('off')\n",
        "        plt.title('Overlay\\n(cyan = detected)', fontsize=12, fontweight='bold')\n",
        "\n",
        "        plt.suptitle(f'Segmentation Results for: {uploaded_path.name}',\n",
        "                     fontsize=14, fontweight='bold', y=1.02)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print()\n",
        "        print(\"-\" * 60)\n",
        "        print(\"FULL RESOLUTION RESULT:\")\n",
        "        print(\"-\" * 60)\n",
        "        print()\n",
        "\n",
        "        mask_fullsize = Image.fromarray((pred_mask * 255).astype(np.uint8))\n",
        "        mask_fullsize = mask_fullsize.resize(orig_size, Image.NEAREST)\n",
        "        print(f\"Mask resized back to original: {orig_size[0]} × {orig_size[1]} pixels\")\n",
        "        print()\n",
        "\n",
        "        fig = plt.figure(figsize=(14, 7))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title('Your Original Image', fontsize=14, fontweight='bold')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        overlay_full = overlay_mask(img, np.array(mask_fullsize), color=(0, 255, 255), alpha=0.5)\n",
        "        plt.imshow(overlay_full)\n",
        "        plt.axis('off')\n",
        "        plt.title('Segmentation Result\\n(Full Resolution)', fontsize=14, fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print()\n",
        "        print(\"=\" * 60)\n",
        "        print(\"STATISTICS:\")\n",
        "        print(\"=\" * 60)\n",
        "        mask_array = np.array(mask_fullsize)\n",
        "        total_pixels = mask_array.size\n",
        "        detected_pixels = np.sum(mask_array > 0)\n",
        "        percentage = (detected_pixels / total_pixels) * 100\n",
        "\n",
        "        print(f\"  • Total pixels: {total_pixels:,}\")\n",
        "        print(f\"  • Detected pixels: {detected_pixels:,}\")\n",
        "        print(f\"  • Coverage: {percentage:.2f}% of image\")\n",
        "        print(f\"  • Average confidence: {prob.mean():.3f}\")\n",
        "        print()\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"ALL DONE! Hope you enjoyed it!\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image: {e}\")\n",
        "        print(\"   Make sure your file is a valid image (JPG, PNG, etc.)\")\n",
        "else:\n",
        "    print()\n",
        "    print(\"=\" * 60)\n",
        "    print(\"NO IMAGE TO PROCESS\")\n",
        "    print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "wezVg1wiBnOz"
      },
      "id": "wezVg1wiBnOz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<small>These images are in the test set: human_bladder_03, human_bladder_09, human_brain_11, human_brain_1, human_brain_9, human_cardia_7, human_epiglottis_2, human_jejunum_04, human_kidney_02, human_kidney_04, human_kidney_06, human_liver_13, human_liver_21, human_liver_22, human_liver_27, human_liver_37, human_liver_39, human_melanoma_08, human_muscle_7, human_oesophagus_11, human_oesophagus_22, human_oesophagus_30, human_oesophagus_34, human_oesophagus_37, human_oesophagus_43, human_pancreas_14, human_pancreas_21, human_pancreas_39, human_peritoneum_6, human_peritoneum_9, human_placenta_26, human_placenta_28, human_placenta_31, human_pylorus_5, human_rectum_10, human_rectum_11, human_rectum_7, human_salivory_11, human_salivory_17, human_salivory_28, human_salivory_32, human_spleen_29, human_testis_10, human_tongue_08, human_tongue_16, human_tongue_17, human_tongue_33, human_tongue_36, human_tonsile_4, human_tonsile_6, human_umbilical_cord_06, mouse_heart_01, mouse_heart_15, mouse_heart_23, mouse_kidney_10, mouse_kidney_19, mouse_kidney_24, mouse_liver_01, mouse_liver_21, mouse_liver_32, mouse_muscle_tibia_02, mouse_muscle_tibia_04, mouse_muscle_tibia_24, mouse_subscapula_16, mouse_subscapula_30, mouse_thymus_01.</small>"
      ],
      "metadata": {
        "id": "zeAnsP564UOb"
      },
      "id": "zeAnsP564UOb"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "test-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}